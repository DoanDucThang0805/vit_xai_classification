# Plant Disease Classification with Vision Transformers and Explainable AI (XAI)

A comprehensive deep learning project for plant disease classification using various neural network architectures with integrated explainable AI techniques. The project includes model training, evaluation, optimization, and interpretability analysis for tomato and pepper disease detection.

## ğŸ“‹ Project Overview

This project aims to classify plant diseases (specifically tomato and pepper) using multiple deep learning models. It combines state-of-the-art architectures with explainable AI methods to understand model predictions, making it useful for agricultural applications.

### Key Features
- **Multiple Model Architectures**: MobilePlantViT, ResNet50, VGG16, DenseNet121, MobileNetV3, ShuffleNetV2, SqueezeNetV2
- **Explainable AI Integration**: GradCAM, LIME, SHAP for model interpretability
- **Dataset Support**: PlantVillage and PlantDoc datasets
- **Model Export**: ONNX format for deployment
- **Performance Benchmarking**: FLOPs, latency, and accuracy metrics
- **Comprehensive Evaluation**: Per-class F1-scores, confusion matrices, and detailed reports

## ğŸ“ Project Structure

```
vit_xai/
â”œâ”€â”€ data/                          # Dataset directories
â”‚   â”œâ”€â”€ PlantVillage/             # PlantVillage dataset (13 classes)
â”‚   â”œâ”€â”€ PlantDoc-Dataset/         # PlantDoc dataset
â”‚   â”œâ”€â”€ cocoplantdoc/             # COCO-format PlantDoc annotations
â”‚   â””â”€â”€ cropped_data/             # Preprocessed cropped images
â”‚
â”œâ”€â”€ checkpoints/                   # Trained model weights
â”‚   â”œâ”€â”€ plantdoc/                 # Models trained on PlantDoc
â”‚   â””â”€â”€ plantvillage/             # Models trained on PlantVillage
â”‚
â”œâ”€â”€ onnx_model/                   # Exported ONNX models
â”‚   â”œâ”€â”€ plantdoc/
â”‚   â””â”€â”€ plant_village/
â”‚
â”œâ”€â”€ reports/                       # Training reports & metrics
â”‚   â”œâ”€â”€ plant_village/
â”‚   â””â”€â”€ plantdoc/
â”‚
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ dataset/                  # Data loading and preprocessing
â”‚   â”‚   â”œâ”€â”€ crop_dataset.py      # Crop images from COCO annotations
â”‚   â”‚   â”œâ”€â”€ dataset.py           # Generic dataset loader
â”‚   â”‚   â””â”€â”€ plantdoc_dataset.py  # PlantDoc-specific loader
â”‚   â”‚
â”‚   â”œâ”€â”€ model/                   # Model architectures
â”‚   â”‚   â”œâ”€â”€ mobilenetv3_small.py
â”‚   â”‚   â”œâ”€â”€ mobileplantvit.py
â”‚   â”‚   â””â”€â”€ vgg16.py
â”‚   â”‚
â”‚   â”œâ”€â”€ trainning/               # Training scripts
â”‚   â”‚   â”œâ”€â”€ trainer.py           # Core Trainer class
â”‚   â”‚   â”œâ”€â”€ mobileplantvit_train.py
â”‚   â”‚   â”œâ”€â”€ resnet50_train.py
â”‚   â”‚   â””â”€â”€ ...other_model_trains
â”‚   â”‚
â”‚   â”œâ”€â”€ inference/               # Inference & evaluation
â”‚   â”‚   â”œâ”€â”€ inference.py         # Model inference
â”‚   â”‚   â”œâ”€â”€ f1score.py           # F1-score calculation
â”‚   â”‚   â””â”€â”€ params.py            # Configuration parameters
â”‚   â”‚
â”‚   â”œâ”€â”€ benchmark/               # Performance evaluation
â”‚   â”‚   â”œâ”€â”€ benchmark.py         # Benchmarking utilities
â”‚   â”‚   â”œâ”€â”€ caculate_flop.py     # FLOPs calculation
â”‚   â”‚   â””â”€â”€ caculate_latency.py  # Latency measurement
â”‚   â”‚
â”‚   â”œâ”€â”€ xai/                     # Explainable AI techniques
â”‚   â”‚   â”œâ”€â”€ gradcam.py           # Gradient-weighted Class Activation Maps
â”‚   â”‚   â”œâ”€â”€ lime.py              # Local Interpretable Model-agnostic Explanations
â”‚   â”‚   â”œâ”€â”€ shap.py              # SHAP values for interpretability
â”‚   â”‚   â”œâ”€â”€ visualize.py         # Visualization utilities
â”‚   â”‚   â””â”€â”€ test.py              # XAI testing
â”‚   â”‚
â”‚   â”œâ”€â”€ metric/                  # Evaluation metrics
â”‚   â”‚   â””â”€â”€ metric.py            # Accuracy and other metrics
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                   # Utility functions
â”‚   â”‚   â””â”€â”€ utils.py             # Helper functions (LoadDataset classes)
â”‚   â”‚
â”‚   â””â”€â”€ export/                  # Model export
â”‚       â””â”€â”€ export_onnx.py       # Export to ONNX format
â”‚
â”œâ”€â”€ notebook/                    # Jupyter notebooks
â”‚   â”œâ”€â”€ prams.ipynb             # Parameter experiments
â”‚   â””â”€â”€ test.ipynb              # Testing & exploration
â”‚
â”œâ”€â”€ images/                     # Project images & visualizations
â”‚
â”œâ”€â”€ trainning.sh               # Main training script
â””â”€â”€ README.md                  # This file
```

## ğŸš€ Getting Started

### Requirements
- Python 3.11
- PyTorch 1.9+
- TorchVision, timm
- NumPy, Pandas, Matplotlib
- Scikit-learn
- OpenCV
- LIME, SHAP, GradCAM libraries
- ONNX, ONNX Runtime

### Installation

```bash
# Clone the repository
git clone <repo-url>
cd vit_xai

# Install dependencies (if using pip)
pip install torch torchvision torchinfo timm # Or appropriate CUDA version
pip install numpy pandas scikit-learn opencv-python pillow matplotlib
pip install lime shap
pip install onnx onnxruntime
```

## ğŸ‹ï¸ Training Models

### Train Single Model

```bash
cd src/

# Train MobilePlantViT on PlantVillage
python -m trainning.mobileplantvit_train

# Train ResNet50
python -m trainning.resnet50_train

# Train VGG16
python -m trainning.vgg16_train

# Train DenseNet121
python -m trainning.densnet_train

# Train MobileNetV3
python -m trainning.mobilenetv3_train

# Train ShuffleNetV2
python -m trainning.shuffelnetv2_train

# Train SqueezeNetV2
python -m trainning.squezzenet_train
```

## ğŸ“Š Evaluation & Inference

### Run Inference

```bash
python -m inference.inference
```

## ğŸ“ˆ Explainable AI (XAI)
```bash
python xai_rp.py  # Run all XAI methods together
```

## ğŸ”„ Model Export to ONNX

Export trained models to ONNX format for deployment:

```bash
cd src/
python -m export.export_onnx.py
```

ONNX models are saved in `onnx_model/` directory.

## ğŸ“ Dataset Details

### PlantVillage
- **Total Classes**: 13
- **Format**: Image files organized in class folders
- **Size**: ~16,600 images
- **Resolution**: 224*224 pixels
- **Location**: `data/PlantVillage/`

### PlantDoc
- **Total Classes**: 8 (tomato diseases)
- **Location**: `data/tomato_only/`

### Data Splitting
- **Train**: 80%
- **Validation**: 10%
- **Test**: 10%


## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“„ License

Specify your license here (MIT, Apache 2.0, etc.)

## ğŸ“§ Contact

For questions or issues, please contact the project maintainer or create an issue on GitHub.

## ğŸ“š References

- Vision Transformers: https://arxiv.org/abs/2010.11929
- GradCAM: https://arxiv.org/abs/1610.02055
- LIME: https://arxiv.org/abs/1602.04938
- SHAP: https://arxiv.org/abs/1705.07874
- PlantVillage Dataset: https://plantvillage.org/
- PlantDoc Dataset: https://github.com/pratikkayal/PlantDoc-Object-Detection-Dataset
