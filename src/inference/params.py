"""
Model Parameter Analysis and Benchmarking.

This module analyzes and compares multiple neural network architectures used for
plant disease classification. It computes:
    - FLOPs (Floating Point Operations)
    - Model parameters count
    - Inference latency
    - Memory usage
    - Model efficiency metrics

Supports multiple architectures:
    - DenseNet121
    - ResNet50
    - MobilePlantVIT
    - VGG16
    - ShuffleNetV2
    - MobileNetV3 Small
    - SqueezeNetV2
"""

import time

import torch
from torch.utils.data import DataLoader
from thop import profile
import pandas as pd
from dataset.dataset import test_dataset

from model.densnet121 import model as DenseNet121
from model.resnet50 import model as ResNet50
from model.mobileplantvit import model as MobilePlantVit
from model.vgg16 import model as VGG16
from model.shufflenet import model as ShuffleNetv2
from model.mobilenetv3_small import model as MobileNetV3_small
from model.squezzenet import model as SqueezeNetv2


# Setup environment: Use CUDA if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: **{device}**")

# 1. Get input size from dataset
try:
    sample_image, _ = test_dataset[0]
    # Send dummy input to selected device (CUDA/CPU)
    dummy_input = sample_image.unsqueeze(0).to(device)
    input_shape = dummy_input.shape
    print(f"Detected input image shape: {input_shape}")
except Exception as e:
    print(f"Error getting image shape: {e}")
    # Create dummy input on selected device
    dummy_input = torch.randn(1, 3, 224, 224).to(device)

# 2. Prepare DataLoader for latency measurement
test_ds = DataLoader(test_dataset, batch_size=1, shuffle=False)
num_images_to_test = 100

# 3. Define dictionary containing imported models
models_to_test = {
    "DenseNet121": DenseNet121,
    "ResNet50": ResNet50,
    "MobilePlantVit": MobilePlantVit,
    "VGG16": VGG16,
    "ShuffleNet": ShuffleNetv2,
    "MobileNetV3_Small": MobileNetV3_small,
    "SqueezeNet": SqueezeNetv2
}

# 4. Measurement loop
results = []

# Kh·ªüi ƒë·ªông (warm-up) v√† setup Event
if device.type == 'cuda':
    print("\nƒêang kh·ªüi ƒë·ªông (warm-up) GPU v√† ƒë·ªìng b·ªô h√≥a...")
    # Warm-up GPU
    with torch.no_grad():
        for _ in range(20):
            if MobilePlantVit:
                model_warmup = MobilePlantVit.to(device).eval()
                _ = model_warmup(dummy_input)
    torch.cuda.synchronize() # ƒê·∫£m b·∫£o m·ªçi t√°c v·ª• warm-up ƒë√£ ho√†n t·∫•t
    
    # Thi·∫øt l·∫≠p CUDA Events ƒë·ªÉ ƒëo th·ªùi gian ch√≠nh x√°c
    start_event = torch.cuda.Event(enable_timing=True)
    end_event = torch.cuda.Event(enable_timing=True)
    
else:
    # N·∫øu l√† CPU, v·∫´n d√πng logic warm-up c≈©
    if MobilePlantVit:
        model_warmup = MobilePlantVit.to(device).eval()
        with torch.no_grad():
            for _ in range(10): 
                _ = model_warmup(dummy_input)
    print("Warm-up ho√†n t·∫•t.")


for name, model in models_to_test.items():
    if model is None:
        print(f"\n--- B·ªè qua m√¥ h√¨nh: **{name}** (Import th·∫•t b·∫°i) ---")
        continue

    print(f"\n--- ƒêang x·ª≠ l√Ω m√¥ h√¨nh: **{name}** ---")
    model = model.to(device).eval()

    # == A. T√≠nh Params v√† FLOPs v·ªõi 'thop' ==
    # THOP LU√îN Y√äU C·∫¶U TH·ª∞C HI·ªÜN TR√äN CPU
    try:
        model_cpu = model.to('cpu')
        input_cpu = dummy_input.to('cpu')
        
        flops, params = profile(model_cpu, inputs=(input_cpu, ), verbose=False)
        
        # CHUY·ªÇN M√î H√åNH TR·ªû L·∫†I DEVICE ƒê·ªÇ ƒêO ƒê·ªò TR·ªÑ (LATENCY)
        model = model_cpu.to(device)

        params_m = params / 1_000_000
        flops_g = flops / 1_000_000_000
        print(f"Params (M): {params_m:,.2f}")
        print(f"FLOPs (G): {flops_g:,.2f}")
    except Exception as e:
        print(f"L·ªói khi t√≠nh FLOPs/Params: {e}")
        params_m = -1
        flops_g = -1

    # == B. ƒêo Inference Latency (ms) == 
    total_time_ms = 0
    images_processed = 0
    
    with torch.no_grad():
        for images, _ in test_ds:
            if images_processed >= num_images_to_test:
                break
            
            images = images.to(device)
            
            # --- LOGIC ƒêO L∆Ø·ªúNG C·∫¨P NH·∫¨T CHO CUDA/CPU ---
            if device.type == 'cuda':
                # D√πng Event cho GPU (b·∫•t ƒë·ªìng b·ªô)
                start_event.record()
                _ = model(images)
                end_event.record()
                torch.cuda.synchronize() # ƒê·ª£i GPU ho√†n t·∫•t
                total_time_ms += start_event.elapsed_time(end_event) # Th·ªùi gian t√≠nh b·∫±ng ms
            else:
                # D√πng time.time() cho CPU (ƒë·ªìng b·ªô)
                start_time = time.time()
                _ = model(images)
                total_time_ms += (time.time() - start_time) * 1000
            # ---------------------------------------------
            
            images_processed += 1
            
    if images_processed == 0:
        print("L·ªói: Kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c b·∫•t k·ª≥ ·∫£nh n√†o.")
        avg_latency_ms = -1
    else:
        avg_latency_ms = total_time_ms / images_processed
        # L√†m tr√≤n k·∫øt qu·∫£ latency
        print(f"Avg. Latency (ms) tr√™n {images_processed} ·∫£nh: **{avg_latency_ms:,.2f}**")

    # L∆∞u k·∫øt qu·∫£
    results.append({
        "Model": name,
        "Params (M)": params_m,
        "FLOPs (G)": flops_g,
        "Latency (ms)": avg_latency_ms
    })

# 5. In k·∫øt qu·∫£ cu·ªëi c√πng
print("\n" + "="*50)
print(" ¬† ¬† ¬† ¬† ¬† ¬† üèÜ B·∫¢NG K·∫æT QU·∫¢ T·ªîNG H·ª¢P üèÜ")
print("="*50)
df_results = pd.DataFrame(results)
print(df_results.to_string(index=False, formatters={
    'Params (M)': '{:,.2f}'.format,
    'FLOPs (G)': '{:,.2f}'.format,
    'Latency (ms)': '{:,.2f}'.format
}))
print("="*50)

# So s√°nh y√™u c·∫ßu
print("\n--- Y√äU C·∫¶U SO S√ÅNH (D·ª±a tr√™n k·∫øt qu·∫£ ƒëo l∆∞·ªùng) ---")
mobile_vit_row = df_results[df_results['Model'] == 'MobilePlantVit']
resnet_row = df_results[df_results['Model'] == 'ResNet50']
vgg16_row = df_results[df_results['Model'] == 'VGG16']

# ... (Ph·∫ßn so s√°nh n√†y gi·ªØ nguy√™n) ...
if not mobile_vit_row.empty and not vgg16_row.empty:
    mobile_vit_latency = mobile_vit_row['Latency (ms)'].values[0]
    vgg16_latency = vgg16_row['Latency (ms)'].values[0]
    print(f"So s√°nh Latency:")
    print(f" ¬†- MobilePlantVit: {mobile_vit_latency:,.2f} ms (M·ª•c ti√™u ~5.3 ms)")
    print(f" ¬†- VGG16: {vgg16_latency:,.2f} ms (M·ª•c ti√™u ~18.7 ms)")
    print(f" ¬†-> MobilePlantVit {'Nhanh h∆°n' if mobile_vit_latency < vgg16_latency else 'Ch·∫≠m h∆°n'} VGG16: {(vgg16_latency / mobile_vit_latency):,.1f} l·∫ßn.")

if not mobile_vit_row.empty and not resnet_row.empty:
    mvp_params = mobile_vit_row['Params (M)'].values[0]
    mvp_flops = mobile_vit_row['FLOPs (G)'].values[0]
    res_params = resnet_row['Params (M)'].values[0]
    res_flops = resnet_row['FLOPs (G)'].values[0]
    print(f"\nX√°c minh t√≠nh m·ªõi (MobilePlantVit vs ResNet50):")
    print(f" ¬†- MobilePlantVit (M·ª•c ti√™u 5.6M, 1.2G): Params={mvp_params:,.2f}M, FLOPs={mvp_flops:,.2f}G")
    print(f" ¬†- ResNet50 (M·ª•c ti√™u 25.6M, 4.1G): Params={res_params:,.2f}M, FLOPs={res_flops:,.2f}G")
    
    param_check = "Th·∫•p h∆°n" if mvp_params < res_params else "Cao h∆°n"
    flop_check = "Th·∫•p h∆°n" if mvp_flops < res_flops else "Cao h∆°n"
    print(f" ¬†-> MobilePlantVit c√≥ Params: **{param_check}** ResNet50.")
    print(f" ¬†-> MobilePlantVit c√≥ FLOPs: **{flop_check}** ResNet50.")