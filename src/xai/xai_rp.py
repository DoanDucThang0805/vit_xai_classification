import torch
import random
from pathlib import Path
import numpy as np

from dataset.dataset import test_dataset
from .metric import *
from .visualize import *

# H√†m th√™m nhi·ªÖu Gaussian (c·∫ßn thi·∫øt cho PSS)
def add_gaussian_noise(image_tensor, sigma=0.01):
    """Th√™m nhi·ªÖu Gaussian v√†o tensor ·∫£nh (C, H, W)."""
    noise = torch.randn_like(image_tensor) * sigma
    noisy_image = image_tensor.float() + noise
    return torch.clamp(noisy_image, 0, 1)

from model.mobilevitxxs import model
model_name = "mobilevitxxs"
num_class = 10
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
project_root = Path(__file__).resolve().parents[2]
checkpoint_path = project_root / 'checkpoints' / 'mobilevitxxs' / 'run_20251122-011952' / 'best_checkpoint.pth'
print(f"ƒêang t·∫£i checkpoint t·ª´: {checkpoint_path}")
if not checkpoint_path.exists():
    raise FileNotFoundError(f"Checkpoint not found: {checkpoint_path}")
checkpoint = torch.load(checkpoint_path, map_location=device)
state_dict = checkpoint.get("model_state_dict", checkpoint.get("state_dict", checkpoint))
model.load_state_dict(state_dict)
model = model.to(device)
model.eval()
print("T·∫£i model th√†nh c√¥ng.")

target_names = [test_dataset.idx_to_class[i] for i in range(len(test_dataset.idx_to_class))]

# ===============================================
# == THI·∫æT L·∫¨P PSS V√Ä OUTPUT ==
# ===============================================
K_PSS = 10 # S·ªë l·∫ßn l·∫∑p ƒë·ªÉ t√≠nh PSS
SIGMA_PSS = 0.01
pss_results = {'gradcam': [], 'lime': [], 'shap': []}

output_path_str = "/media/icnlab/Data/Thang/plan_dieases/vit_xai/reports/xai/mobilevitxxs"
output_dir = Path(output_path_str)
output_dir.mkdir(parents=True, exist_ok=True)
print(f"K·∫øt qu·∫£ s·∫Ω ƒë∆∞·ª£c l∆∞u v√†o th∆∞ m·ª•c: {output_dir.resolve()}")

# --- Ch·ªçn 50 ·∫£nh ng·∫´u nhi√™n ---
num_samples_to_run = 50
dataset_size = len(test_dataset)

if dataset_size < num_samples_to_run:
    print(f"C·∫£nh b√°o: Dataset ch·ªâ c√≥ {dataset_size} ·∫£nh. S·∫Ω ch·∫°y tr√™n to√†n b·ªô dataset.")
    num_samples_to_run = dataset_size
    random_indices = list(range(dataset_size))
else:
    random_indices = random.sample(range(dataset_size), num_samples_to_run)

print("-" * 50)
print(f"B·∫Øt ƒë·∫ßu ch·∫°y so s√°nh v√† t√≠nh PSS cho {num_samples_to_run} ·∫£nh ng·∫´u nhi√™n...")
print("-" * 50)

for i, idx in enumerate(random_indices):
    print(f"\nƒêang x·ª≠ l√Ω ·∫£nh {i+1}/{num_samples_to_run} (Dataset Index: {idx})...")
    
    image, true_label = test_dataset[idx] # image (CPU tensor)
    
    # Danh s√°ch ƒë·ªÉ l∆∞u tr·ªØ K=10 b·∫£n ƒë·ªì cho PSS
    gradcam_maps, lime_maps, shap_maps = [], [], []

    # üí• V√íNG L·∫∂P PSS (K=10)
    for k in range(K_PSS):
        # 1. Th√™m nhi·ªÖu v√† chuy·ªÉn ·∫£nh nhi·ªÖu l√™n GPU/CPU t∆∞∆°ng ·ª©ng
        noisy_image = add_gaussian_noise(image, sigma=SIGMA_PSS)
        image_gpu_noisy = noisy_image.to(device)
        
        # 2. Ch·∫°y XAI tr√™n ·∫£nh nhi·ªÖu
        # Grad-CAM (d√πng ·∫£nh nhi·ªÖu GPU)
        gradcam_maps.append(gradcam_explain(model, image_gpu_noisy, label=true_label, device=device))
        
        # LIME/SHAP (d√πng ·∫£nh nhi·ªÖu CPU - s·∫Ω ƒë∆∞·ª£c chuy·ªÉn l√™n GPU b√™n trong h√†m)
        lime_maps.append(lime_explain(model, noisy_image, label=true_label, device=device))
        shap_maps.append(shap_explain(model, noisy_image, label=true_label, device=device))
    

    with torch.no_grad():
        outputs = model(image.to(device).unsqueeze(0))
        pred_label = outputs.argmax(dim=1).item()
    
    true_name = target_names[true_label]
    pred_name = target_names[pred_label]
    print(f"  True Label: {true_name} | Predicted Label: {pred_name}")
    
    # 3. T√≠nh PSS
    pss_gradcam = calculate_pss(gradcam_maps)
    pss_lime = calculate_pss(lime_maps)
    pss_shap = calculate_pss(shap_maps)
    
    # 4. L∆∞u PSS c·ªßa ·∫£nh hi·ªán t·∫°i
    pss_results['gradcam'].append(pss_gradcam)
    pss_results['lime'].append(pss_lime)
    pss_results['shap'].append(pss_shap)
    
    print(f"  PSS - GradCAM: {pss_gradcam:.4f} | LIME: {pss_lime:.4f} | SHAP: {pss_shap:.4f}")
    
    # 5. Visualize (d√πng b·∫£n ƒë·ªì ƒë·∫ßu ti√™n v√† ·∫£nh g·ªëc)
    gradcam_map_vis = gradcam_maps[0]
    lime_map_vis = lime_maps[0]
    shap_map_vis = shap_maps[0]
    
    true_name_safe = true_name.replace(" ", "_").replace("/", "-")
    save_filename = f"{model_name}_compare_idx_{idx}_{true_name_safe}.png"
    save_path = output_dir / save_filename
    
    # üí• TRUY·ªÄN PSS V√ÄO VISUALIZE:
    visualize_comparison(
        image, 
        gradcam_map_vis, 
        lime_map_vis, 
        shap_map_vis,
        true_label, 
        pred_label, 
        target_names,
        save_path,
        pss_gradcam=pss_gradcam,
        pss_lime=pss_lime,
        pss_shap=pss_shap 
    )
    print(f"  ‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {save_path}")

# ===============================================
# == T·ªîNG K·∫æT PSS CU·ªêI C√ôNG ==
# ===============================================
print("-" * 50)
print(f"‚úÖ Ho√†n t·∫•t! ƒê√£ l∆∞u {num_samples_to_run} ·∫£nh so s√°nh v√†o th∆∞ m·ª•c '{output_dir.name}'.")
print("-" * 50)
print("üìà K·∫æT QU·∫¢ ƒê√ÅNH GI√Å ƒê·ªäNH L∆Ø·ª¢NG (PSS Trung b√¨nh):")
print(f"   PSS Trung B√¨nh (Grad-CAM): {np.mean(pss_results['gradcam']):.4f}")
print(f"   PSS Trung B√¨nh (LIME): {np.mean(pss_results['lime']):.4f}")
print(f"   PSS Trung B√¨nh (SHAP): {np.mean(pss_results['shap']):.4f}")
print("-" * 50)